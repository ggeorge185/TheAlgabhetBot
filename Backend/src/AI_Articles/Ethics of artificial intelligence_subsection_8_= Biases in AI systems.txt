Main|Algorithmic bias}}
File:Kamala Harris speaks about racial bias in artificial intelligence - 2020-04-23.ogg|thumb|Then-US Senator [[Kamala Harris speaking about racial bias in artificial intelligence in 2020]]
AI has become increasingly inherent in facial and speech recognition|voice recognition systems. Some of these systems have real business applications and directly impact people. These systems are vulnerable to biases and errors introduced by its human creators. Also, the data used to train these AI systems itself can have biases. For instance, Facial recognition system|facial recognition algorithms made by Microsoft, IBM and Face++ all had biases when it came to detecting people's gender; these AI systems were able to detect gender of white men more accurately than gender of darker skin men. Further, a 2020 study reviewed voice recognition systems from Amazon, Apple, Google, IBM, and Microsoft found that they have higher error rates when transcribing black people's voices than white people's. Furthermore, Amazon (company)|Amazon terminated their use of Artificial intelligence in hiring|AI hiring and recruitment because the algorithm favored male candidates over female ones. This was because Amazon's system was trained with data collected over 10-year period that came mostly from male candidates.

