Research on embodied cognition and learning suggests that learning could occur and be triggered by perception-action interactions of the body with the surrounding environment. An embodied cognitive approach to child development provides insights into how infants attain spatial knowledge and develop spatial skills that allow them to (successfully) interact with the world around them. Most infants learn to walk in the first 18 months of life, which draws on ample new opportunities for exploring things around them. In this exploration, infants learn spatial relations, and by carrying objects from one place to another, they may also learn affordances such as "transportability". Thereafter, new phases in exploration may occur through which infants can discover other even more elaborate affordances. Further research indicates that mere observational experience by infants does not produce these results. Similarly, research has shown how action and bodily movements can be used as Scaffolding|scaffolds for learning. A study investigating whether infants at high risk for developing autism spectrum disorders (ASD) could benefit from action scaffolded interventions (reaching experiences) during early development indicates an increase in grasping activity following training. And thus, it provides evidence about the possibility for high-risk of ASD infants to learn and respond to action-based treatment interventions. Another study investigates how teaching methods can benefit from embodiment and proposes that a professor's movements and gestures contribute to learning by growing students' embodied experiences in the classroom, leading to an increased capacity to recall.

The action-based language theory (ABL) states that aspects of embodiment are also relevant for language learning and acquisition. ABL proposes that the brain exploits the same mechanisms used in motor control for language learning. When adults, for example, call attention to an object and an infant follows the lead and attends to said object, canonical neurons are activated and affordances of an object become available to the infant. Simultaneously, hearing the articulation of the object's name leads to the activation of speech mirror mechanisms in infants. This chain of events allows for Hebbian theory|Hebbian learning of the meaning of verbal labels by linking the speech and action controllers, which get activated in this scenario.

The role of gestures in learning is another example of the importance of embodiment for cognition. Gestures can aid, facilitate and enhance learning performance, or compromise it when the gestures are restricted or meaningless to the content that is being transmitted. In a study using the Tower of Hanoi|Tower of Hanoi (TOH) puzzle, participants were divided into two groups. In the first part of the experiment, the smallest disks used in TOH were the lightest and could be moved using just one hand. For the second part, this was reversed for one group (switch group) so that the smallest disks were the heaviest, and participants needed both hands to move them. The disks remained the same for the other group (no-switch group). After the experiment ended, participants were asked to explain their solution while researchers monitored their gestures when describing their solution. The results showed that using gestures affected the performance of the switch group in the second part of the experiment. The more they used one-handed gestures to depict their solution in the first part of the experiment, the worse they performed in the second part.

A study investigating the role of gestures in second language learning states that learning the vocabulary with self-performed gestures increases learning outcomes. The enduring benefits continued even after two and six months post-learning. In addition, the same study also investigated the neural correlates of learning a second language with gestures. The results indicate that Premotor cortex|left premotor areas and the superior temporal sulcus (a brain region responsible for visual processing of biological motion) were activated during learning with gestures. Similarly, an Functional magnetic resonance imaging|fMRI study showed that children who learned to solve mathematical problems using a speech and gesture strategy were more likely to have activation in motor regions of the brain. The activation of motor regions occurred during scans in which children were not using gestures to solve the problems. These findings indicate that learning with gestures creates a neural trace of the motor system that goes beyond the learning phase and activates when children engage with problems they learned to solve with gestures.

Embodied cognition has also been linked to both reading and writing. Research shows that physical and perceptual engagements congruent with the content of the reading material can boost reading comprehension. Findings also suggest that the benefits accrued from handwriting as compared to typing in letter recognition and written communication result from the more embodied nature of handwriting.

