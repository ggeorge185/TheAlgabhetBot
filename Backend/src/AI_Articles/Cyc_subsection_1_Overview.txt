The need for a massive symbolic artificial intelligence project of this kind was born in the early 1980s. Early AI researchers had ample experience over the previous 25 years with AI programs that would generate encouraging early results but then fail to "scale up"â€”move beyond the 'training set' to tackle a broader range of cases. Douglas Lenat and Alan Kay publicized this need,   The US Government reacted to the Fifth Generation threat by passing the National Cooperative Research and Production Act|National Cooperative Research Act of 1984, which for the first time allowed US companies to "collude" on long-term high-risk high-payoff research, and Microelectronics and Computer Technology Corporation|MCC and SEMATECH|Sematech sprang up to take advantage of that ten-year opportunity.  MCC's first President and CEO was Bobby Ray Inman, former NSA Director and Central Intelligence Agency deputy director.

The objective of the Cyc project was to codify, in machine-usable form, the millions of pieces of knowledge that compose human common sense.  This entailed, along the way, (1) developing an adequately expressive representation language, CycL, (2) developing an ontology spanning all human concepts down to some appropriate level of detail, (3) developing a knowledge base on that ontological framework, to be able to infer the same types and depth of conclusions that humans are capable of, given their knowledge of the world.

In slightly more detail:
* The CycL representation language started as an extension of RLL (the so-called Representation Language Language, developed in 1979&ndash;1980 by Lenat and his graduate student Russell Greiner while at Stanford University), but within a few years of the launch of the Cyc project it became clear that even representing a typical news story or novel or advertisement would require more than the expressive power of full first-order logic, namely Second-order logic|second-order predicate calculus ("What is the relationship between rain and water?") and then even higher-level orders of logic including modal logic, reflection (enabling the system to reason about its progress so far, on a problem on which it's working), and context logic (enabling the system to reason explicitly about the contexts in which its various premises and conclusions might hold), non-monotonic logic, and Circumscription (logic)|circumscription.  By 1989,
** Some of these HL modules are very general, such as a module that caches the Kleene star|Kleene Star (transitive closure) of all the commonly-used transitive relations in Cyc's ontology.
** Some are domain-specific, such as a chemical equation-balancer.  These can be and often are an "escape" to (pointer to) some externally available program or webservice or online database, such as a module to quickly "compute" the current population of a city by knowing where/how to look that up.

CycL has a publicly released specification and dozens of HL modules were described in Lenat and Guha's textbook,

The name "Cyc" (from "encyclopedia", pronounced , like "''syke''") is a registered trademark owned by Cycorp. Access to Cyc is through paid licenses, but ''bona fide'' AI research groups are given research-only no-cost licenses (cf. ResearchCyc); as of 2017, over 600 such groups worldwide have these licenses.

Typical pieces of knowledge represented in the Cyc knowledge base are "Every tree is a plant" and "Plants die eventually". When asked whether trees die, the inference engine can draw the obvious conclusion and answer the question correctly.

Most of Cyc's knowledge, outside math, is only true by default.  For example,  Cyc knows that ''as a default'' parents love their children, when you're made happy you smile, taking your first step is a big accomplishment, when someone you love has a big accomplishment that makes you happy, and only adults have children.  When asked whether a picture captioned "Someone watching his daughter take her first step" contains a smiling adult person, Cyc can logically infer that the answer is ''Yes'', and "show its work" by presenting the step by step logical argument using those five pieces of knowledge from its knowledge base.  These are formulated in the language CycL, which is based on predicate calculus and has a syntax similar to that of the Lisp (programming language)|Lisp programming language.

In 2008, Cyc resources were mapped to many Wikipedia articles. Cyc is presently connected to Wikidata. Future plans may connect Cyc to both DBpedia and Freebase (database)|Freebase.

Much of the current work Cyc continues to be knowledge engineering, representing facts about the world by hand, and implementing efficient inference mechanisms on that knowledge. Increasingly, however, work at Cycorp involves giving the Cyc system the ability to communicate with end users in natural language, and to assist with the ongoing knowledge formation process via machine learning and natural-language understanding.  Another large effort at Cycorp is building a suite of Cyc-powered Ontology engineering|ontological engineering tools to lower the bar to entry for individuals to contribute to, edit, browse, and query Cyc.

Like many companies, Cycorp has ambitions to use Cyc's natural language processing|natural-language processing to parse the entire internet to extract structured data; unlike all others, it is able to call on the Cyc system itself to act as an inductive bias and as an adjudicator of ambiguity, metaphor, and Ellipsis (linguistics)|ellipsis.  There are few, if any, systematic benchmark studies of Cyc's performance.

