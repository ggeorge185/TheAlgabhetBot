Main|Lethal autonomous weapon|Artificial intelligence arms race|AI safety}}

A lethal autonomous weapon is a machine that locates, selects and engages human targets without human supervision.}} By 2015, over fifty countries were reported to be researching battlefield robots. These weapons are considered especially dangerous for several reasons: if they murder|kill an innocent person it is not clear who should be held accountability|accountable, it is unlikely they will reliably choose targets, and, if produced at scale, they are potentially weapons of mass destruction. In 2014, 30 nations (including China) supported a ban on autonomous weapons under the United Nations' Convention on Certain Conventional Weapons, however the United States and others disagreed.

AI provides a number of tools that are particularly useful for authoritarian governments: smart spyware, Facial recognition system|face recognition and Speaker recognition|voice recognition allow widespread surveillance; such surveillance allows machine learning to classifier (machine learning)|classify potential enemies of the state and can prevent them from hiding; recommender system|recommendation systems can precisely target propaganda and misinformation for maximum effect; deepfakes and generative AI aid in producing misinformation; advanced AI can make authoritarian technocracy|centralized decision making more competitive with liberal and decentralized systems such as market (economics)|markets.

AI facial recognition systems are used for mass surveillance, notably in China. In 2019, Bangalore|Bengaluru, India deployed AI-managed traffic signals. This system uses cameras to monitor traffic density and adjust signal timing based on the interval needed to clear traffic. Terrorists, criminals and rogue states can use weaponized AI such as advanced digital warfare and lethal autonomous weapons. Machine-learning AI is also able to design tens of thousands of toxic molecules in a matter of hours.

