Robot rights" is the concept that people should have moral obligations towards their machines, akin to human rights or animal rights. It has been suggested that robot rights (such as a right to exist and perform its own mission) could be linked to robot duty to serve humanity, analogous to linking human rights with human duties before society. These could include the Personhood|right to life and liberty, freedom of thought and expression, and equality before the law. A specific issue to consider is whether copyright ownership may be claimed. The issue has been considered by the Institute for the Future and by the Department of Trade and Industry (United Kingdom)|U.K. Department of Trade and Industry.
	 
Experts disagree on how soon specific and detailed laws on the subject will be necessary. while Ray Kurzweil sets the date at 2029. Another group of scientists meeting in 2007 supposed that at least 50 years had to pass before any sufficiently advanced system would exist.
	 
The rules for the 2003 Loebner Prize competition envisioned the possibility of robots having rights of their own:

<blockquote>61. If in any given year, a publicly available open-source Entry entered by the University of Surrey or the Cambridge Center wins the Silver Medal or the Gold Medal, then the Medal and the Cash Award will be awarded to the body responsible for the development of that Entry. If no such body can be identified, or if there is disagreement among two or more claimants, the Medal and the Cash Award will be held in trust until such time as the Entry may legally possess, either in the United States of America or in the venue of the contest, the Cash Award and Gold Medal in its own right. </blockquote>
	 	
In October 2017, the android Sophia (robot)|Sophia was granted citizenship in Saudi Arabia, though some considered this to be more of a publicity stunt than a meaningful legal recognition. Some saw this gesture as openly denigrating of human rights and the rule of law.
	 
The philosophy of Sentientism grants degrees of moral consideration to all sentient beings, primarily humans and most non-human animals. If artificial or alien intelligence show evidence of being Sentience|sentient, this philosophy holds that they should be shown compassion and granted rights.
	 
Joanna Bryson has argued that creating AI that requires rights is both avoidable, and would in itself be unethical, both as a burden to the AI agents and to human society.

