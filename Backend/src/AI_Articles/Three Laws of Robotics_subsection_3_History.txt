In ''The Rest of the Robots'', published in 1964, Isaac Asimov noted that when he began writing in 1940 he felt that "one of the stock plots of science fiction was&nbsp;... robots were created and destroyed their creator. Knowledge has its dangers, yes, but is the response to be a retreat from knowledge? Or is knowledge to be used as itself a barrier to the dangers it brings?" He decided that in his stories a robot would not "turn stupidly on his creator for no purpose but to demonstrate, for one more weary time, the crime and punishment of Faust."

On May 3, 1939, Asimov attended a meeting of the Queens (New York (state)|New York) Science Fiction Society where he met Eando Binder|Earl and Otto Binder who had recently published a short story I, Robot (short story)|"I, Robot" featuring a sympathetic robot named Adam Link who was misunderstood and motivated by love and honor. (This was the first of a series of ten stories; the next year "Adam Link's Vengeance" (1940) featured Adam thinking "A robot must never kill a human, of his own free will.") Asimov admired the story. Three days later Asimov began writing "my own story of a sympathetic and noble robot", his 14th story. Thirteen days later he took "Robbie (short story)|Robbie" to John W. Campbell the editor of ''Analog Science Fiction and Fact|Astounding Science-Fiction''. Campbell rejected it, claiming that it bore too strong a resemblance to Lester del Rey's "Helen O'Loy", published in December 1938—the story of a robot that is so much like a person that she falls in love with her creator and becomes his ideal wife. Frederik Pohl published the story under the title “Strange Playfellow” in ''Super Science Stories'' September 1940.

Asimov attributes the Three Laws to John W. Campbell, from a conversation that took place on 23 December 1940. Campbell claimed that Asimov had the Three Laws already in his mind and that they simply needed to be stated explicitly. Several years later Asimov's friend Randall Garrett attributed the Laws to a symbiosis|symbiotic partnership between the two men -a suggestion that Asimov adopted enthusiastically. According to his autobiographical writings, Asimov included the First Law's "inaction" clause because of Arthur Hugh Clough's poem "The Latest Decalogue" (:s:The Latest Decalogue|text in Wikisource), which includes the satirical lines "Thou shalt not kill, but needst not strive / officiously to keep alive".

Although Asimov pins the creation of the Three Laws on one particular date, their appearance in his literature happened over a period. He wrote two robot stories with no explicit mention of the Laws, "Robbie (short story)|Robbie" and "Reason (Asimov)|Reason". He assumed, however, that robots would have certain inherent safeguards. "Liar! (short story)|Liar!", his third robot story, makes the first mention of the First Law but not the other two. All three laws finally appeared together in "Runaround (story)|Runaround". When these stories and several others were compiled in the anthology ''I, Robot'', "Reason" and "Robbie" were updated to acknowledge all the Three Laws, though the material Asimov added to "Reason" is not entirely consistent with the Three Laws as he described them elsewhere. In particular the idea of a robot protecting human lives when it does not believe those humans truly exist is at odds with Elijah Baley's reasoning, as described #Ambiguities and loopholes|below.

During the 1950s Asimov wrote a series of science fiction novels expressly intended for young-adult audiences. Originally his publisher expected that the novels could be adapted into a long-running television series, something like ''The Lone Ranger'' had been for radio. Fearing that his stories would be adapted into the "uniformly awful" programming he saw flooding the television channels Asimov decided to publish the Lucky Starr series|''Lucky Starr'' books under the pseudonym "Paul French". When plans for the television series fell through, Asimov decided to abandon the pretence; he brought the Three Laws into ''Lucky Starr and the Moons of Jupiter'', noting that this "was a dead giveaway to Paul French's identity for even the most casual reader".

In his short story Evidence (Asimov)|"Evidence" Asimov lets his recurring character Susan Calvin|Dr. Susan Calvin expound a morality|moral basis behind the Three Laws. Calvin points out that human beings are typically expected to refrain from harming other human beings (except in times of extreme duress like war, or to save a greater number) and this is equivalent to a robot's First Law. Likewise, according to Calvin, society expects individuals to obey instructions from recognized authorities such as doctors, teachers and so forth which equals the Second Law of Robotics. Finally humans are typically expected to avoid harming themselves which is the Third Law for a robot.

The plot of "Evidence" revolves around the question of telling a human being apart from a robot constructed to appear human. Calvin reasons that if such an individual obeys the Three Laws he may be a robot or simply "a very good man". Another character then asks Calvin if robots are very different from human beings after all. She replies, "Worlds different. Robots are essentially decent."

Asimov later wrote that he should not be praised for creating the Laws, because they are "obvious from the start, and everyone is aware of them subliminally. The Laws just never happened to be put into brief sentences until I managed to do the job. The Laws apply, as a matter of course, to every tool that human beings use", and "analogues of the Laws are implicit in the design of almost all tools, robotic or not":

# Law 1: A tool must not be unsafe to use. Hammers have handles and screwdrivers have hilts to help increase grip. It is of course possible for a person to injure himself with one of these tools, but that injury would only be due to his incompetence, not the design of the tool.
# Law 2: A tool must perform its function efficiently unless this would harm the user. This is the entire reason ground-fault circuit interrupters exist. Any running tool will have its power cut if a circuit senses that some current is not returning to the neutral wire, and hence might be flowing through the user. The safety of the user is paramount.
# Law 3: A tool must remain intact during its use unless its destruction is required for its use or for safety. For example, Dremel disks are designed to be as tough as possible without breaking unless the job requires it to be spent. Furthermore, they are designed to break at a point before the shrapnel velocity could seriously injure someone (other than the eyes, though safety glasses should be worn at all times anyway).

Asimov believed that, ideally, humans would also follow the Laws:



Asimov stated in a 1986 interview on the Manhattan public access show ''Conversations with Harold Hudson Channer with Harold Channer'' with guest co-host Marilyn vos Savant, "It's a little humbling to think that, what is most likely to survive of everything I've said... After all, I've published now... I've published now at least 20 million words.  I'll have to figure it out, maybe even more.  But of all those millions of words that I've published, I am convinced that 100 years from now only 60 of them will survive.  The 60 that make up the Three Laws of Robotics."

