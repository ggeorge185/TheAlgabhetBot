There are many social, ethical and legal implications of automated decision-making systems. Concerns raised include lack of transparency and contestability of decisions, incursions on privacy and surveillance, exacerbating systemic bias and inequality due to data and algorithmic bias, intellectual property rights, the spread of misinformation via media platforms, administrative discrimination, risk and responsibility, unemployment and many others. As ADM becomes more ubiquitous there is greater need to address the ethical challenges to ensure good governance in information societies.

ADM systems are often based on machine learning and algorithms which are not easily able to be viewed or analysed, leading to concerns that they are 'black box' systems which are not transparent or accountable. GDPR also includes some rules on the right to explanation however the exact scope and nature of these is currently subject to pending review by the Court of Justice of the European Union. These provisions were not first introduced in the GDPR, but have been present in a similar form across Europe since the Data Protection Directive in 1995, and the 1978 French law, the . Similarly scoped and worded provisions with varying attached rights and obligations are present in the data protection laws of many other jurisdictions across the world, including Uganda, Morocco and the US state of Virginia.
* Rights for the explanation of public sector automated decisions forming 'algorithmic treatment' under the French loi pour une République numérique.
* Emergent bias, where the application of ADM in unanticipated circumstances creates a biased outcome

