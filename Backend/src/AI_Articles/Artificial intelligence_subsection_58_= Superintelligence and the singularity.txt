SUPERINTELLIGENCE -->
A superintelligence is a hypothetical agent that would possess intelligence far surpassing that of the brightest and most gifted human mind.

<!-- SINGULARITY -->
If research into artificial general intelligence produced sufficiently intelligent software, it might be able to reprogram and improve itself. The improved software would be even better at improving itself, leading to what I. J. Good called an "intelligence explosion" and Vernor Vinge called a "Technological singularity|singularity".

<!-- ANTI-SINGULARITIANISM -->
However, technologies cannot improve exponentially indefinitely, and typically follow an S-shaped curve, slowing when they reach the physical limits of what the technology can do.

