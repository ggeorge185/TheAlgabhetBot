In the early seventies, the capabilities of AI programs were limited. Even the most impressive could only handle trivial versions of the problems they were supposed to solve; all the programs were, in some sense, "toys". AI researchers had begun to run into several fundamental limits that could not be overcome in the 1970s. Although some of these limits would be conquered in later decades, others still stymie the field to this day.
* '''Limited computer power''': There was not enough memory or processing speed to accomplish anything truly useful. For example, Ross Quillian's successful work on natural language was demonstrated with a vocabulary of only ''twenty'' words, because that was all that would fit in memory. Hans Moravec argued in 1976 that computers were still millions of times too weak to exhibit intelligence. He suggested an analogy: artificial intelligence requires computer power in the same way that aircraft require horsepower. Below a certain threshold, it's impossible, but, as power Moore's law|increases, eventually it could become easy. With regard to computer vision, Moravec estimated that simply matching the Edge detection|edge and motion detection capabilities of human retina in real time would require a general-purpose computer capable of 10<sup>9</sup> operations/second (1000 MIPS). As of 2011, practical computer vision applications require 10,000 to 1,000,000 MIPS. By comparison, the fastest supercomputer in 1976, Cray-1 (retailing at $5 million to $8 million), was only capable of around 80 to 130 MIPS, and a typical desktop computer at the time achieved less than 1 MIPS.
* '''Intractability (complexity)|Intractability and the combinatorial explosion'''. In 1972 Richard Karp (building on Stephen Cook's 1971 Cook's theorem|theorem) showed there are Karp's 21 NP-complete problems|many problems that can probably only be solved in exponential time (in the size of the inputs). Finding optimal solutions to these problems requires unimaginable amounts of computer time except when the problems are trivial. This almost certainly meant that many of the "toy" solutions used by AI would probably never scale up into useful systems.
* '''Commonsense knowledge and commonsense reasoning|reasoning'''. Many important artificial intelligence applications like computer vision|vision or natural language require simply enormous amounts of information about the world: the program needs to have some idea of what it might be looking at or what it is talking about. This requires that the program know most of the same things about the world that a child does. Researchers soon discovered that this was a truly ''vast'' amount of information. No one in 1970 could build a database so large and no one knew how a program might learn so much information.
* '''Moravec's paradox''': Proving theorems and solving geometry problems is comparatively easy for computers, but a supposedly simple task like recognizing a face or crossing a room without bumping into anything is extremely difficult. This helps explain why research into machine vision|vision and robotics had made so little progress by the middle 1970s.
* '''The frame problem|frame and qualification problems'''. AI researchers (like John McCarthy (computer scientist)|John McCarthy) who used logic discovered that they could not represent ordinary deductions that involved automated planning and scheduling|planning or default reasoning without making changes to the structure of logic itself. They developed new logics (like non-monotonic logics and modal logics) to try to solve the problems.

