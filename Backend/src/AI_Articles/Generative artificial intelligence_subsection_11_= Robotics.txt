Generative AI can also be trained on the motions of a robotic system to generate new trajectories for motion planning or Robot navigation|navigation. For example, UniPi from Google Research uses prompts like ''"pick up blue bowl"'' or ''"wipe plate with yellow sponge"'' to control movements of a robot arm. Multimodal "vision-language-action" models such as Google's RT-2 can perform rudimentary reasoning in response to user prompts and visual input, such as picking up a toy dinosaur when given the prompt ''pick up the extinct animal'' at a table filled with toy animals and other objects.

