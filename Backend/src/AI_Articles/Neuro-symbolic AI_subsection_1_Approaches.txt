Approaches for integration are diverse. Henry Kautz's taxonomy of neuro-symbolic architectures, which constructs a neural network from an And–or tree|AND-OR proof tree generated from knowledge base rules and terms. Logic Tensor Networks also fall into this category.
* '''Neural[Symbolic]'''—allows a neural model to directly call a symbolic reasoning engine, e.g., to perform an action or evaluate a state. An example would be ChatGPT using a Plug-in (computing)|plugin to query Wolfram Alpha.

These categories are not exhaustive, as they do not consider multi-agent systems. In 2005, Bader and Pascal Hitzler|Hitzler presented a more fine-grained categorization that considered, e.g., whether the use of symbols included logic and if it did, whether the logic was Propositional calculus|propositional or first-order logic. The 2005 categorization and Kautz's taxonomy above are compared and contrasted in a 2021 article. Recently, Sepp Hochreiter argued that Graph neural network|Graph Neural Networks "...are the predominant models of neural-symbolic computing" since "[t]hey describe the properties of molecules, simulate social networks, or predict future states in physical and engineering applications with particle-particle interactions."<sup>[https://dl.acm.org/doi/pdf/10.1145/3512715]</sup>

