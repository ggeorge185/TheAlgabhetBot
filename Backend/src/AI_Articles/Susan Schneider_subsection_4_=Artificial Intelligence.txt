In her book ''Artificial You: AI and the Future of Your Mind,'' Schneider discusses different theories of artificial intelligence (AI) and consciousness, and speculates about the ethical, philosophical, and scientific implications of AI for humanity. She argues that AI will inevitably change our understanding of intelligence, and may also change us in ways that we do not anticipate, intend, or desire. She advocates for a cautious and thoughtful approach to transhumanism. She emphasizes that people must make careful choices to ensure that sentient beings - whether human or android - flourish. Using AI technology to reshape the human brain or to build machine minds, will mean experimenting with "tools" that we do not understand how to use: the mind, the self, and consciousness. Schneider argues that failing to understand fundamental philosophical issues will jeopardize the beneficial use of AI and brain enhancement technology, and may lead to the suffering or death of conscious beings. To flourish, humans must address the philosophical issues underlying  the AI algorithms.

In the domain of astrobiology, Schneider contends that the most intelligent alien beings we encounter will be "postbiological in nature", being forms of artificial intelligence, that they would be superintelligent, and that we can predict what the shape of some of these superintelligences would be like. Her reason for the claim that the most intelligent aliens will be "postbiological" is called the "short window observation." The short-window supposition holds that by the time any society learns to transmit radio signals, they're likely just a few hundred years from upgrading their own biology.

In an earlier technical book on the computational nature of the brain with MIT Press, ''The Language of Thought: a New Philosophical Direction'' (2011), Schneider examines the viability of different computational theories of thinking. Expanding on the work of Jerry Fodor, with whom she had studied, she suggests revisions to the symbol processing approach known as the "language of thought hypothesis" (LOTH) or "language of thought" (LOT). Drawing on both computational neuroscience and  cognitive psychology, Scheider argues that the brain may be a hybrid computational system.

'''<big>Testing AI:</big>'''

To determine whether something is conscious we must perform dedicated tests in order to come to a conclusion. The Turing test was developed in an attempt to solve the puzzle of testing thinking, not consciousness. This test was developed far before the first artificial intelligence were made and does not answer the true question of consciousness. The idea behind the Turing test was that if it could have a conversation, then it could think. However this is far too restrictive. Much like the "seagull test" just because it looks like a seagull doesn't mean it can fly. Due to these faults, a new test had to be created. When it comes to machine minds, Schneider has developed her own personal opinions on machine consciousness. She believed that we should test computer consciousness with a variety of different tests. The two main tests Schneider shares her opinions about are the ACT test and her chip test. These test aim to defeat the faults that plague the Turing test.

'''<big>Chip Test:</big>'''

The Chip test, unlike the Turing test Focuses on the parts inside the machine and not just its behaviors. She thinks that if a machine has the same parts that could support a human consciousness, we should consider that it might also have a consciousness and be conscious. This means that if the machine could contain parts that had the capability to support consciousness, then it would be possible to be conscious. the issue with this test is that if we replaced someone's brain with a silicon chip, then we ask them if they are conscious, there is nothing stopping the chip from emitting a sound that says "yes I am conscious". They could act exactly as they did before, simply without consciousness.

'''<big>ACT test:</big>'''

The ACT test is responsible for determining consciousness based on verbal behavior, more specifically; verbal behavior concerning the metaphysics of consciousness. The machine will be tested on its ability to have philosophical ideas and thoughts, whether it thinks of the afterlife and whether we have a soul or not etc. If the machine could have these profound thoughts without being taught to do so, then it would be conscious. If a machine is not truly conscious, then it would perform these tests very poorly. However this test has its faults as well. The test relies on the idea that the machine would not have been fed any information of any kind. The issue lies however, not in the computer but in humans, since we have been fed information from the moment we were born. Our philosophy has been constructed by the things and ideas around us. So while we may think philosophically about what happens when we die, the computer may be thinking of something completely different. So if a machine was not fed any information at all, or even info different form ours, then we could not compare them to us.

