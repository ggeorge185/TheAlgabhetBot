Tay was released on Twitter on March 23, 2016, under the name TayTweets and handle @TayandYou. It was presented as "The AI with zero chill". Tay started replying to other Twitter users, and was also able to caption photos provided to it into Internet meme#Image macros|a form of Internet memes. ''Ars Technica'' reported Tay experiencing topic "blacklisting": Interactions with Tay regarding "certain hot topics such as Killing of Eric Garner|Eric Garner (killed by New York police in 2014) generate safe, canned answers".

Some Twitter users began tweeting politically incorrect phrases, teaching it inflammatory messages revolving around common themes on the internet, such as "Red pill and blue pill#As political metaphor|redpilling" and "Gamergate controversy|Gamergate". As a result, the robot began releasing Racism|racist and Flirting|sexually-charged messages in response to other Twitter users. Many of Tay's inflammatory tweets were a simple exploitation of Tay's "repeat after me" capability. Abby Ohlheiser of ''The Washington Post'' theorized that Tay's research team, including editorial staff, had started to influence or edit Tay's tweets at some point that day, pointing to examples of almost identical replies by Tay, asserting that "Gamergate controversy|Gamer Gate sux. Gender equality|All genders are equal and should be treated fairly." A "#JusticeForTay" campaign protested the alleged editing of Tay's tweets. and after Tay had tweeted more than 96,000 times, Microsoft suspended the Twitter account for adjustments, saying that it suffered from a "coordinated attack by a subset of people" that "exploited a vulnerability in Tay."

Madhumita Murgia of ''The Daily Telegraph|The Telegraph'' called Tay "a public relations disaster", and suggested that Microsoft's strategy would be "to label the debacle a well-meaning experiment gone wrong, and ignite a debate about the hatefulness of Twitter users." However, Murgia described the bigger issue as Tay being "artificial intelligence at its very worst - and it's only the beginning".

On March 25, Microsoft confirmed that Tay had been taken offline. Microsoft released an apology on its official blog for the controversial tweets posted by Tay. Microsoft was "deeply sorry for the unintended offensive and hurtful tweets from Tay", and would "look to bring Tay back only when we are confident we can better anticipate malicious intent that conflicts with our principles and values".

