File:Power-Seeking Image.png|thumb|upright=1.3|Advanced misaligned AI systems would have an incentive to seek power in various ways, since power would help them accomplish their given objective.
Since the 1950s, AI researchers have striven to build advanced AI systems that can achieve large-scale goals by predicting the results of their actions and making long-term Automated planning and scheduling|plans. Some AI researchers argue that suitably advanced planning systems will seek power over their environment, including over humansâ€”for example, by evading shutdown, proliferating, and acquiring resources. Such power-seeking behavior is not explicitly programmed but emerges because power is instrumental in achieving a wide range of goals. Power-seeking is considered a Instrumental convergence|''convergent instrumental goal'' and can be a form of specification gaming. Leading computer scientists such as Geoffrey Hinton have argued that future power-seeking AI systems could pose an existential risk.

Power-seeking is expected to increase in advanced systems that can foresee the results of their actions and strategically plan. Mathematical work has shown that optimal reinforcement learning agents will seek power by seeking ways to gain more options (e.g. through self-preservation), a behavior that persists across a wide range of environments and goals.

Power-seeking has emerged in some real-world systems. Reinforcement learning systems have gained more options by acquiring and protecting resources, sometimes in unintended ways. Some language models seek power in text-based social environments by gaining money, resources, or social influence. Furthermore, it is debated whether future AI systems will pursue goals and make long-term plans. Similarly, political leaders may see an advance in developing powerful AI systems that can outmaneuver adversaries through planning. Alternatively, long-term planning might emerge as a byproduct because it is useful e.g. for models that are trained to predict the actions of humans who themselves perform long-term planning. Nonetheless, the majority of AI systems may remain myopic and perform no long-term planning.}} It is also debated whether power-seeking AI systems would be able to disempower humanity.

