Having clarified the question, Turing turned to answering it: he considered the following nine common objections, which include all the major arguments against artificial intelligence raised in the years since his paper was first published.

#''Religious Objection'': This states that thinking is a function of man's Immortality|immortal soul; therefore, a machine cannot think.  "In attempting to construct such machines," wrote Turing, "we should not be irreverently usurping His power of creating souls, any more than we are in the procreation of children: rather we are, in either case, instruments of His will providing mansions for the souls that He creates."
#'' 'Heads in the Sand' Objection'': "The consequences of machines thinking would be too dreadful.  Let us hope and believe that they cannot do so."  This thinking is popular among intellectual people, as they believe superiority derives from higher intelligence and Existential risk from artificial general intelligence|the possibility of being overtaken is a threat (as machines have efficient memory capacities and processing speed, machines exceeding the learning and knowledge capabilities are highly probable). This objection is a fallacious appeal to consequences, confusing what should not be with what can or cannot be (Wardrip-Fruin, 56).
#''The Mathematics|Mathematical Objection'': This objection uses mathematical theorems, such as GÃ¶del's incompleteness theorem, to show that there are limits to what questions a computer system based on logic can answer.  Turing suggests that humans are too often wrong themselves and pleased at the fallibility of a machine.  (This argument would be made again by philosopher John Lucas (philosopher)|John Lucas in 1961 and physicist Roger Penrose in 1989.)
#''Argument From Consciousness'': This argument, suggested by Professor Geoffrey Jefferson in his 1949 Lister Medal|Lister Oration (acceptance speech for his 1948 award of Lister Medal) states that "not until a machine can write a sonnet or compose a concerto because of thoughts and emotions felt, and not by the chance fall of symbols, could we agree that machine equals brain."  Turing replies by saying that we have no way of knowing that any individual other than ourselves experiences emotions, and that therefore we should accept the test.  He adds, "I do not wish to give the impression that I think there is no mystery about consciousness ... [b]ut I do not think these mysteries necessarily need to be solved before we can answer the question [of whether machines can think]." (This argument, that a computer can't have ''conscious experiences'' or ''understanding'', would be made in 1980 by philosopher John Searle in his Chinese room argument. Turing's reply is now known as the "problem of other minds|other minds reply". See also Philosophy of artificial intelligence#Can a machine have a mind, consciousness and mental states?|Can a machine have a mind? in the philosophy of AI.)
#''Arguments from various disabilities''. These arguments all have the form "a computer will never do ''X''". Turing offers a selection:<blockquote>Be kind, resourceful, beautiful, friendly, have initiative, have a sense of humour, tell right from wrong, make mistakes, fall in love, enjoy strawberries and cream, make someone fall in love with it, learn from experience, use words properly, be the subject of its own thought, have as much diversity of behaviour as a man, do something really new.</blockquote>Turing notes that "no support is usually offered for these statements," and that they depend on naive assumptions about how versatile machines may be in the future, or are "disguised forms of the argument from consciousness." He chooses to answer a few of them:
##''Machines cannot make mistakes.'' He notes it's easy to program a machine to appear to make a mistake.
##''A machine cannot be the subject of its own thought'' (or can't be self-aware). A program which can report on its internal states and processes, in the simple sense of a debugger program, can certainly be written. Turing asserts "a machine can undoubtably be its own subject matter."
##''A machine cannot have much diversity of behaviour''. He notes that, with enough storage capacity, a computer can behave in an astronomical number of different ways.
#''Ada Lovelace|Lady Lovelace's Objection'': One of the most famous objections states that computers are incapable of originality. This is largely because, according to Ada Lovelace, machines are incapable of independent learning.<blockquote>The Analytical Engine has no pretensions whatever to ''originate'' anything. It can do whatever ''we know how to order it'' to perform. It can follow analysis; but it has no power of anticipating any analytical relations or truths.</blockquote> Turing suggests that Lovelace's objection can be reduced to the assertion that computers "can never take us by surprise" and argues that, to the contrary, computers could still surprise humans, in particular where the consequences of different facts are not immediately recognizable. Turing also argues that Lady Lovelace was hampered by the context from which she wrote, and if exposed to more contemporary scientific knowledge, it would become evident that the brain's storage is quite similar to that of a computer.
#''Argument from continuity in the nervous system'': Modern neurological research has shown that the brain is not digital. Even though neurons fire in an all-or-nothing pulse, both the exact timing of the pulse and the probability of the pulse occurring have analog components. Turing acknowledges this, but argues that any analog system can be simulated to a reasonable degree of accuracy given enough computing power. (Philosopher Hubert Dreyfus would make this argument against "the biological assumption" in 1972.)
#''Argument from the informality of behaviour'': This argument states that any system governed by laws will be predictable and therefore not truly intelligent. Turing replies by stating that this is confusing laws of behaviour with general rules of conduct, and that if on a broad enough scale (such as is evident in man) machine behaviour would become increasingly difficult to predict. He argues that, just because we can't immediately see what the laws are, does not mean that no such laws exist. He writes "we certainly know of no circumstances under which we could say, 'we have searched enough. There are no such laws.'". (Hubert Dreyfus would argue in 1972 that human reason and problem solving was not based on formal rules, but instead relied on instincts and awareness that would never be captured in rules. More recent AI research in robotics and computational intelligence attempts to find the complex rules that govern our "informal" and unconscious skills of perception, mobility and pattern matching. See Dreyfus' critique of AI). This rejoinder also includes the Turing's Wager argument.
#''Extra-sensory perception'': In 1950, extra-sensory perception was an active area of research and Turing chooses to give ESP the benefit of the doubt, arguing that conditions could be created in which Telepathy|mind-reading would not affect the test. Turing admitted to "overwhelming statistical evidence" for telepathy, likely referring to early 1940s experiments by Samuel Soal, a member of the Society for Psychical Research.

