Existential risks are defined as "risks that threaten the destruction of humanity's long-term potential." The instantiation of an existential risk (an ''existential catastrophe'') would either cause outright human extinction or irreversibly lock in a drastically inferior state of affairs. Existential risks are a sub-class of global catastrophic risks, where the damage is not only ''global'' but also ''terminal'' and ''permanent,'' preventing recovery and thereby affecting both current and all future generations. A disaster severe enough to cause the permanent, irreversible collapse of human civilisation would constitute an existential catastrophe, even if it fell short of extinction. Bryan Caplan writes that "perhaps an eternity of totalitarianism would be worse than extinction". an example.) A dystopian scenario shares the key features of extinction and unrecoverable collapse of civilization: before the catastrophe humanity faced a vast range of bright futures to choose from; after the catastrophe, humanity is locked forever in a terrible state. Moreover, many catastrophic risks change rapidly as technology advances and background conditions, such as geopolitical conditions, change. Another challenge is the general difficulty of accurately predicting the future over long timescales, especially for anthropogenic risks which depend on complex human political, economic and social systems.

