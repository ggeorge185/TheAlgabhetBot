Check Point Research and others noted that ChatGPT could write phishing emails and malware, especially when combined with OpenAI Codex. CyberArk researchers demonstrated that ChatGPT could be used to create polymorphic malware that could evade security products while requiring little effort by the attacker. From the launch of ChatGPT in the fourth quarter of 2022 to the fourth quarter of 2023, there was a 1,265% increase in malicious phishing emails and a 967% increase in credential phishing, which cybersecurity professionals argued in an industry survey was attributable to cybercriminals' increased use of generative artificial intelligence (including ChatGPT). Researchers at Purdue University analyzed ChatGPT responses to 517 questions about software engineering or computer programming posed on Stack Overflow for correctness, consistency, comprehensiveness, and conciseness, and found that 52% of ChatGPT responses contained inaccuracies and 77% were verbose. Similarly, researchers at Stanford University and the University of California, Berkeley found that, when creating directly Execution (computing)|executable responses to the latest 50 Code generation (compiler)|code generation problems from LeetCode that were rated as "easy", the performances of GPT-3.5 and GPT-4 fell from 22% and 52%, respectively, in March 2023, to 2% and 10%, respectively, in June 2023.

