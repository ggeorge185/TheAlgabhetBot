Main articles|Artificial consciousness}}

Digital sentience (or artificial sentience) means the sentience of Artificial intelligence|artificial intelligences. The question of whether artificial intelligences can be sentient is controversial. 

The AI research community does not consider sentience (that is, the "ability to feel sensations") as an important research goal, unless it can be shown that consciously "feeling" a sensation can make a machine more intelligent than just receiving input from sensors and processing it as information. Stuart J. Russell|Stuart Russell and Peter Norvig wrote in 2021: "We are interested in programs that behave intelligently. Individual aspects of consciousness -- awareness, self-awareness, attention -- can be programmed and can be part of an intelligent machine. The additional project making a machine conscious in exactly the way humans are is not one that we are equipped to take on." 
Indeed, leading AI textbooks do not mention "sentience" at all.

Digital sentience is of considerable interest to the philosophy of mind. Functionalism (philosophy of mind)|Functionalist philosophers consider that sentience is about "causal roles" played by mental states, which involve information processing. In this view, the physical substrate of this information processing does not need to be biological, so there is no theoretical barrier to the possibility of sentient machines. According to type physicalism however, the physical constitution is important ; and depending on the types of physical systems required for sentience, it may or may not be possible for certain types of machines (such as electronic computing devices) to be sentient.

The discussion on the topic of alleged sentience of artificial intelligence has been reignited in 2022 by the claims made about Google's LaMDA (Language model|Language Model for Dialogue Applications) artificial intelligence system that it is "sentient" and had a "soul." LaMDA is an Artificial Intelligence System|artificial intelligence system that creates chatbots – AI robots designed to communicate with humans – by gathering vast amounts of text from the internet and using Algorithm|algorithms to respond to queries in the most fluid and natural way possible. The transcripts of conversations between scientists and LaMDA reveal that the AI system excels at this, providing answers to challenging topics about the nature of Emotion|emotions, generating Aesop's Fables|Aesop-style fables on the moment, and even describing its alleged fears.

In 2022, the philosopher David Chalmers made a speech on whether large language model|large language models (LLMs) can be conscious, encouraging more research on the subject. He said that it is very plausible that the training of AI models can cause a world model to emerge in them. He personally estimated the chances that the most advanced LLMs are conscious to be less than 10% in 2022 and more than 20% in 2032, reaching around 50% if it attains "virtual perception, language, action, unified agents" exceeding the cognition level of a fish. He stated that "If you see conscious A.I. coming somewhere down the line, then that's going to raise a whole new important group of extremely snarly ethical challenges with, you know, the potential for new forms of injustice".

Nick Bostrom considers that while LaMDA is probably not sentient, being very sure of it would require understanding how consciousness works, having access to unpublished information about LaMDA's architecture, and finding how to apply the philosophical theory on the machine. He also said about LLMs that "it's not doing them justice to say they're simply regurgitating text", noting that they "exhibit glimpses of creativity, insight and understanding that are quite impressive and may show the rudiments of reasoning". He thinks that "sentience is a matter of degree". It defines sentience as the relationship between the information processing rate of each individual processing unit (neuron), the weight/size of a single unit, and the total number of processing units (expressed as mass). It was proposed as a measure for the sentience of all living beings and computers from a single neuron up to a hypothetical being at the theoretical computational limit of the entire universe. On a logarithmic scale it runs from −70 up to +50.

