The Stanford Institute for Human-Centered Artificial Intelligence's (HAI) Center for Research on Foundation Models (CRFM) coined the term "foundation model" in August 2021 to mean "any model that is trained on broad data (generally using self-supervision at scale) that can be adapted (e.g., fine-tuned) to a wide range of downstream tasks". After considering many terms, they settled on "foundation model" to emphasize the intended ''function'' (i.e., amenability to subsequent further development) rather than Modality (human–computer interaction)|modality, architecture, or implementation. The term “foundation model” was chosen over “foundational model” because “foundational” implies that these models provide fundamental principles in a way that “foundation” does not.

As governments regulate foundation models, new legal definitions have emerged. 

* In the United States, the ''Executive Order 14110|Executive Order on the Safe, Secure, and Trustworthy Development and Use of Artificial Intelligence'' defines a foundation model as “an AI model that is trained on broad data; generally uses Self-supervised learning|self-supervision; contains at least tens of billions of parameters; is applicable across a wide range of contexts”. 
* In the European Union, the European Parliament’s negotiated position on the Artificial Intelligence Act|E.U. AI Act defines a foundation model as an “AI model that is trained on broad data at scale, is designed for generality of output, and can be adapted to a wide range of distinctive tasks”. 
* In the United Kingdom, the Competition and Markets Authority’s ''AI Foundation Models: Initial Report''   For text-to-image generation, an approach called textual inversion can be similarly used to teach the system new concept that can later be generated in conjunction with the concepts that the foundation model is already familiar with.

