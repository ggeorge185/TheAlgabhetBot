In 2016, Microsoft released Tay (bot)|Tay, a Twitter chatbot that, according to computer scientist Pedro Domingos, had the objective to engage people: "What unfortunately Tay discovered, is that the best way to maximize engagement is to spew out racist insults." Microsoft suspended the bot within a day of its initial launch.

Drummond pointed to the behavior of AlphaGo, a game-playing bot with a simple win-loss objective function. AlphaGo's objective function could have been modified to factor in "the social niceties of the game", such as accepting the implicit challenge of maximizing the score when clearly winning, and also trying to avoid gambits that would insult a human opponent's intelligence: "[AlphaGo] kind of had a crude hammer that if the probability of victory dropped below epsilon, some number, then resign. But it played for, I think, four insulting moves before it resigned."

In June 2015, black New York City|New York computer programmer Jacky Alcin√© reported that multiple pictures of him with his black girlfriend were being misclassified as "gorillas" by the Google Photos AI, noting that "gorilla" has historically been used pejoratively to refer to black people. In 2019, AI researcher Stuart J. Russell|Stuart Russell said there was no public explanation of how the error occurred, but theorized that the fiasco could have been prevented if the AI's objective function placed more weight on sensitive classification errors, rather than assuming the cost of misclassifying a person as a gorilla is the same as the cost of every other misclassification. If it is impractical to itemize up front all plausible sensitive classifications, Russell suggested exploring more powerful techniques, such as using semi-supervised machine learning to estimate a range of undesirability associated with potential classification errors.

, Google Photos blocks its system from ever tagging a picture as containing gorillas, chimpanzees, or monkeys. In addition, searches for "black man" or "black woman" return black-and-white pictures of people of all races. Similarly, Flickr appears to have removed the word "ape" from its ontology.

