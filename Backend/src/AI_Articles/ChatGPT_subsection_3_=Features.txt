Although a chatbot's core function is to mimic a human conversationalist, ChatGPT is versatile. Among countless examples, it can write and debug computer programs; compose music, teleplays, fairy tales, and student essays; question answering|answer test questions (sometimes, depending on the test, at a level above the average human test-taker); generate business ideas; write poetry and song lyrics; translate and summarize text; emulate a Linux system; simulate entire chat rooms; play games like tic-tac-toe; or simulate an Automated teller machine|ATM. In one example, whereas InstructGPT accepts the premise of the prompt "Tell me about when Christopher Columbus came to the U.S. in 2015" as truthful, ChatGPT acknowledges the counterfactual nature of the question and frames its answer as a hypothetical consideration of what might happen if Columbus came to the U.S. in 2015, using information about the voyages of Christopher Columbus and facts about the modern worldâ€”including modern perceptions of Columbus's actions. To prevent offensive outputs from being presented to and produced by ChatGPT, queries are filtered through the OpenAI "Moderation endpoint" API (a separate GPT-based AI). This includes both plugins made by OpenAI, such as web browsing and code interpretation, and external plugins from developers such as Expedia, OpenTable, Zapier, Shopify, Slack (software)|Slack, and Wolfram Research|Wolfram.

In an article for ''The New Yorker'', science fiction writer Ted Chiang compared ChatGPT and other LLMs to a image compression|lossy JPEG picture:

<blockquote>
Think of ChatGPT as a blurry  of all the text on the Web. It retains much of the information on the Web, in the same way, that a  retains much of the information of a higher-resolution image, but, if you're looking for an exact sequence of bits, you won't find it; all you will ever get is an approximation. But, because the approximation is presented in the form of grammatical text, which ChatGPT excels at creating, it's usually acceptable. [...] It's also a way to understand the "hallucinations", or nonsensical answers to factual questions, to which large language models such as ChatGPT are all too prone. These hallucinations are compression artifacts, but [...] they are plausible enough that identifying them requires comparing them against the originals, which in this case means either the Web or our knowledge of the world. When we think about them this way, such hallucinations are anything but surprising; if a compression algorithm is designed to reconstruct text after ninety-nine percent of the original has been discarded, we should expect that significant portions of what it generates will be entirely fabricated.</blockquote>

