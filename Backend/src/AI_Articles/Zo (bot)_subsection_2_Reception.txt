Zo came under criticism for the biases introduced in an effort to avoid potentially offensive subjects. The chatbot refuses for example to engage with any mention—be it positive, negative or neutral—of the Middle East, the Qur'an or the Torah, while allowing discussion of Christianity. In an article in ''Quartz (publication)|Quartz'' where she exposed those biases, Chloe Rose Stuart-Ulin wrote, "Zo is politically correct to the worst possible extreme; mention any of her triggers, and she transforms into a judgmental little brat."

