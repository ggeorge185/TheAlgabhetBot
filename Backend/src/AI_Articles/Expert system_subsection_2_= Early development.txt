Soon after the dawn of modern computers in the late 1940s and early 1950s, researchers started realizing the immense potential these machines had for modern society.  One of the first challenges was to make such machines capable of “thinking” like humans – in particular, making these machines capable of making important decisions the way humans do.  The medical/healthcare field presented the tantalizing challenge of enabling these machines to make medical diagnostic decisions.

Thus, in the late 1950s, right after the information age had fully arrived, researchers started experimenting with the prospect of using computer technology to emulate human decision making. For example, biomedical researchers started creating computer-aided systems for diagnostic applications in medicine and biology. These early diagnostic systems used patients’ symptoms and laboratory test results as inputs to generate a diagnostic outcome.
These systems were often described as the early forms of expert systems.  However, researchers realized that there were significant limitations when using traditional methods such as flow charts,
 statistical pattern matching, or probability theory.

