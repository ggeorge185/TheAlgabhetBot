On finite graphs with non-negative edge weights A* is guaranteed to terminate and is ''complete'', i.e. it will always find a solution (a path from start to goal) if one exists. On infinite graphs with a finite branching factor and edge costs that are bounded away from zero (<math display="inline">d(x,y)>\varepsilon>0</math> for some fixed <math>\varepsilon</math>), A* is guaranteed to terminate only if there exists a solution.
They considered a variety of  definitions of '''Alts''' and '''P'''  in combination with A*'s heuristic being merely admissible or being both Consistent heuristic|consistent and admissible.  The most interesting positive result they proved is that A*, with a consistent heuristic, is optimally efficient with respect to all admissible A*-like search algorithms on all "non-pathological" search problems.  Roughly speaking, their notion of the non-pathological problem is what we now mean by "up to tie-breaking".  This result does not hold if A*'s heuristic is admissible but not consistent. In that case, Dechter and Pearl showed there exist admissible A*-like algorithms that can expand arbitrarily fewer nodes than A* on some non-pathological problems.

Optimal efficiency is about the ''set'' of nodes expanded, not the ''number'' of node expansions (the number of iterations of A*'s main loop).  When the heuristic being used is admissible but not consistent, it is possible for a node to be expanded by A* many times, an exponential number of times in the worst case.
In such circumstances, Dijkstra's algorithm could outperform A* by a large margin. However, more recent research found that this pathological case only occurs in certain contrived situations where the edge weight of the search graph is exponential in the size of the graph and that certain inconsistent (but admissible) heuristics can lead to a reduced number of node expansions in A* searches.

