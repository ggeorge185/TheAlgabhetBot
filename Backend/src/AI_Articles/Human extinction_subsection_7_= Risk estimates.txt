Given the limitations of ordinary observation and modeling, Delphi method|expert elicitation is frequently used instead to obtain probability estimates. 

* Humanity has a 95% probability of being extinct in 7,800,000 years, according to J. Richard Gott's formulation of the controversial doomsday argument, which argues that we have probably already lived through half the duration of human history.
* In 1996, John A. Leslie estimated a 30% risk over the next five centuries (equivalent to around 6% per century, on average).
* In 2003, Martin Rees estimated a 50% chance of collapse of civilisation in the twenty-first century.
* A 2008 survey by the Future of Humanity Institute estimated a 5% probability of extinction by super-intelligence by 2100.
* The Global Challenges Foundation's 2016 annual report estimates an annual probability of human extinction of at least 0.05% per year (equivalent to 5% per century, on average). 
* A 2016 survey of AI experts found a median estimate of 5% that human-level AI would cause an outcome that was "extremely bad (e.g. human extinction)". In 2019, the risk was lowered to 2%, but in 2022, it was increased back to 5%. In 2023, the risk doubled to 10%.
* In 2020, Toby Ord estimates existential risk in the next century at "1 in 6" in his book ''The Precipice: Existential Risk and the Future of Humanity''. He also estimated a "1 in 10" risk of extinction by unaligned AI within the next century.
* According to the July 10, 2023 article of ''The Economist'', scientists estimated a 12% chance of AI-caused catastrophe and a 3% chance of AI-caused extinction by 2100. They also estimate a 8% chance of Nuclear War causing global catastrophe and a 0.5625% chance of Nuclear War causing Human Extinction. 
* In May 1, 2023, The Treaty on Artificial Intelligence Safety and Cooperation (TAISC) has estimated a 30.5% risk of an AI-caused catastrophe by 2200, although they also estimate a 32.2% risk of an AI-caused catastrophe by 2026, if there is no 6 month moratorium. 
* As of November 19, 2023, Metaculus users estimate a 1% probability of human extinction by 2100.
* In a 2010 interview with ''The Australian'', Australian scientist Frank Fenner predicted the extinction of the human race within a century, primarily as the result of human overpopulation, environmental degradation and climate change. 
* According to a 2020 study published in ''Scientific Reports'', if deforestation and resource Overconsumption|consumption continue at current rates, they could culminate in a "catastrophic collapse in human population" and possibly "an irreversible collapse of our civilization" in the next 20 to 40 years. According to the most optimistic scenario provided by the study, the chances that human civilization survives are smaller than 10%. To avoid this collapse, the study says, humanity should pass from a civilization dominated by the economy to a "cultural society" that "privileges the interest of the ecosystem above the individual interest of its components, but eventually in accordance with the overall communal interest." 
* Nick Bostrom, a philosopher at the University of Oxford known for his work on existential risk, argues that it would be "misguided" to assume that the probability of near-term extinction is less than 25% and that it will be "a tall order" for the human race to "get our precautions sufficiently right the first time", given that an existential risk provides no opportunity to learn from failure. Leslie also discusses the anthropic survivorship bias (which he calls an "observational selection" effect on page 139) and states that the ''A priori and a posteriori|a priori'' certainty of observing an "undisastrous past" could make it difficult to argue that we must be safe because nothing terrible has yet occurred. He quotes Holger Bech Nielsen's formulation: "We do not even know if there should exist some extremely dangerous decay of say the proton which caused the eradication of the earth, because if it happens we would no longer be there to observe it and if it does not happen there is nothing to observe."
* Jean-Marc Salotti calculated the probability of human extinction caused by a giant asteroid impact. It is between 0.03 and 0.3 for the next billion years, if there is no colonization of other planets. According to that study, the most frightening object is a giant long-period comet with a warning time of a few years only and therefore no time for any intervention in space or settlement on the Moon or Mars. The probability of a giant comet impact in the next hundred years is 2.2E-12.

