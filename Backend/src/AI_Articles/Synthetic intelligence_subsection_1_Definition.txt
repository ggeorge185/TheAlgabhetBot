The term was used<!-- did he coin it? --> by Haugeland in 1986 to describe artificial intelligence research up to that point, which he called "GOFAI|good old fashioned artificial intelligence" or "GOFAI". AI's first generation of researchers firmly believed their techniques would lead to real, human-like intelligence in machines. After the first AI winter, many AI researchers shifted their focus from artificial general intelligence to finding solutions for specific individual problems, such as machine learning, an approach to which some popular sources refer as "weak AI" or "applied AI." 

The term "synthetic AI" is now sometimes used by researchers in the field to separate their work (using Subsymbolic|subsymbolism, recursive self-improvement|emergence, Psi-Theory, or other relatively new methods to define and create "true" intelligence) from previous attempts, particularly those of GOFAI or weak AI.

Sources disagree about exactly what constitutes "real" intelligence as opposed to "simulated" intelligence and therefore whether there is a meaningful distinction between artificial intelligence and synthetic intelligence. Russell and Norvig present this example:
# "Can machines fly?" The answer is yes, because airplanes fly.
# "Can machines swim?" The answer is no, because submarines don't swim.
# "Can machines think?" Is this question like the first, or like the second?

Drew McDermott firmly believes that "thinking" should be construed like "flying". While discussing the electronic chess champion Deep Blue (chess computer)|Deep Blue, he argues "Saying Deep Blue doesn't really think about chess is like saying an airplane doesn't really fly because it doesn't flap its wings." Edsger Dijkstra agrees that some find "the question whether machines can think as relevant as the question whether submarines can swim."

John Searle, on the other hand, suggests that a thinking machine is, at best, a ''simulation'', and writes "No one supposes that computer simulations of a five-alarm fire will burn the neighborhood down or that a computer simulation of a rainstorm will leave us all drenched." The essential difference between a simulated mind and a real mind is one of the key points of his Chinese room argument.

Daniel Dennett believes that this is basically a disagreement about semantics, peripheral to the central questions of the philosophy of artificial intelligence. He notes that even a chemically perfect imitation of a Chateau Latour is still a fake, but that any vodka is real, no matter who made it. Similarly, a perfect, molecule-by-molecule recreation of an original Picasso would be considered a "forgery", but any image of the Coca-Cola|Coca-Cola logo is completely real and subject to trademark laws. Russell and Norvig comment "we can conclude that in some cases, the behavior of an artifact is important, while in others it is the artifact's pedigree that matters. Which one is important in which case seems to be a matter of convention. But for artificial minds, there is no convention."

